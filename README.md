# Combining GAN with reverse correlation to construct personalized facial expressions
This is the official implementation of our journal [paper](https://) "Combining GAN with reverse correlation to construct personalized facial expressions".

For more information, please refer to our project website: [Mental-Deep-Reverse-Engineering](https://yansen0508.github.io/emotional-prototype/).

<p style="color: red;">[Update: 14/08/2023] Paper was accepted by Plos One.</p>

<p style="color: red;">I am on vacation in August. The code will be available soon.</p>


## Approach


## Requirements
Please install Pytorch, Torchvision, [Psychopy](https://www.psychopy.org/), and dependencies.
```shell
pip install -r requirements.txt
```

## Description
The generator is based on [GANimation](https://github.com/albertpumarola/GANimation).
The interface of the perceptual experiment is based on Psychopy.

The input image and the output images are 148 * 148.

<span style="background-color: #f1f1f1; padding: 5px;"><code>datasets/results/</code></span>:
All the generated images can be found in <span style="background-color: #f1f1f1; padding: 5px;"><code>test_ganimation_30</code></span>.

<span style="background-color: #f1f1f1; padding: 5px;"><code>datasets/test/imgs/</code></span>: image folder.

<span style="background-color: #f1f1f1; padding: 5px;"><code>datasets/test/aus_openface_new560.pkl</code></span>: dictionary containing the action units of each image.

<span style="background-color: #f1f1f1; padding: 5px;"><code>datasets/test/train_ids.csv</code></span>: the file containing the names of the images to be used to train.

<span style="background-color: #f1f1f1; padding: 5px;"><code>datasets/test/test_ids.csv</code></span>: the file containing the names of the images to be used to test.

<span style="background-color: #f1f1f1; padding: 5px;"><code>csv/</code></span>: containing all the trial information.

<span style="background-color: #f1f1f1; padding: 5px;"><code>subject/</code></span>: 560 different faces are generated by activating 3 out of 16 action units. 
Example subject comes from [MMI datasets](https://mmifacedb.eu/).

<span style="background-color: #f1f1f1; padding: 5px;"><code>*.txt</code></span>: texts displayed during the perceptual experiments.

Please download the pretrained model from [here](https://drive.google.com/file/d/1f9moiWKiyPMJ9wtrihJY6yeAKVed9SXg/view?usp=sharing) and [here](https://drive.google.com/file/d/1geTeVf0v8was3GdBjLbeTnv_uLpbLPl6/view?usp=sharing).  Then put them at <span style="background-color: #f1f1f1; padding: 5px;"><code>ckpts/190327_160828/</code></span>

### To run: 

## Citation
If you use this code or ideas from the paper for your research, please cite our paper:
```BibTeX
@article{yan2023combining,
  title={Combining GAN with reverse correlation to construct personalized facial expressions},
  author={Yan, Sen and Soladie, Catherine and Aucouturier, Jean-Julien and Seguier, Renaud},
  journal={PloS one},
  volume={},
  number={},
  pages={},
  year={2023},
  publisher={Public Library of Science San Francisco, CA USA}
}
```

## Acknowledgement
This work is supported by Randstad and ANR REFLETS.
![CentraleSupelec](Figs/logo1.png)
![Randstad](Figs/logo2.png)
